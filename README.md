# CS231A-project

## Aim
The main aim of this project is to understand and visualize how people's head and facial movement is corrolated with how they are percieved by others on the categories of: extroversion, iagreeableness, conscientiousness, neuroticism, and openness to experience
We are using data from the Cha-Learn challenge which includes 15 second snippets of people talking tagged by Mechanical Turk workers on the traits from 0 to 1 

## Methodology 
For each frame we extract 68 feature points in the face 
using the script 
## Directories / Files
